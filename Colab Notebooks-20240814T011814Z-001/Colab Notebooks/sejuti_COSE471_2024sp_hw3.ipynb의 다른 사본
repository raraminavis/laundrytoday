{"cells":[{"cell_type":"markdown","metadata":{"id":"uchZsTUr-c9r"},"source":["# HW 3: Spam/Ham Classification\n","## Due Date: 5/13 (Mon), 11:59 PM\n","\n","**Collaboration Policy**\n","\n","Data science is a collaborative activity. While you may talk with others about\n","the project, we ask that you **write your solutions individually**. If you do\n","discuss the assignments with others please **include their names** at the top\n","of your notebook."]},{"cell_type":"markdown","metadata":{"id":"BZm3TdH3-c9s"},"source":["**Collaborators**: *list collaborators here*"]},{"cell_type":"markdown","metadata":{"id":"npb43RFZ-c9s"},"source":["## This Assignment\n","In this homework, you will use what you've learned in class to create a classifier that can distinguish spam (junk or commercial or bulk) emails from ham (non-spam) emails. In addition to providing some skeleton code to fill in, we will evaluate your work based on your model's accuracy and your written responses in this notebook.\n","\n","After this homework, you should feel comfortable with the following:\n","\n","- Part 1: Feature engineering with text data\n","- Part 2: Using sklearn libraries to process data and fit models\n","- Part 3: Validating the performance of your model and minimizing overfitting\n","- Part 3: Generating and analyzing precision-recall curves\n","\n","## <span style=\"color:red\">Warning!</span>\n","We've tried our best to filter the data for anything blatantly offensive as best as we can, but unfortunately there may still be some examples you may find in poor taste. If you encounter these examples and believe it is inappropriate for students, please let a TA know and we will try to remove it for future semesters. Thanks for your understanding!"]},{"cell_type":"markdown","metadata":{"id":"zyVLHHS3-c9t"},"source":["## Score Breakdown\n","Question | Points\n","--- | ---\n","1a | 2\n","1b | 2\n","1c | 2\n","2 | 3\n","3 | 3\n","4 | 3\n","5 | 3\n","6a | 3\n","6b | 3\n","6c | 3\n","6d | 3\n","7 | 4\n","8 | 4\n","Total | 38"]},{"cell_type":"markdown","metadata":{"id":"lGGE7QCC-c9t"},"source":["# Part I - Initial Analysis"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"-O2DiZBt-c9t","executionInfo":{"status":"ok","timestamp":1716193122650,"user_tz":-540,"elapsed":1454,"user":{"displayName":"김민경","userId":"05552883468747004724"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import seaborn as sns\n","sns.set(style = \"whitegrid\",\n","        color_codes = True,\n","        font_scale = 1.5)\n","\n","class bcolor:\n","   BLACK = '\\033[40m'\n","   YELLOW = '\\033[93m'\n","   RED = '\\033[91m'\n","   BOLD = '\\033[1m'\n","   END = '\\033[0m'\n","\n","def print_passed(str_in):\n","  print(bcolor.BLACK + bcolor.YELLOW + bcolor.BOLD + str_in + bcolor.END)"]},{"cell_type":"markdown","metadata":{"id":"tOKYwC_X_Tom"},"source":["## Mount your Google Drive\n","When you run a code cell, Colab executes it on a temporary cloud instance.  Every time you open the notebook, you will be assigned a different machine.  All compute state and files saved on the previous machine will be lost.  Therefore, you may need to re-download datasets or rerun code after a reset. Here, you can mount your Google drive to the temporary cloud instance's local filesystem using the following code snippet and save files under the specified directory (note that you will have to provide permission every time you run this)."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":388},"id":"JpuWdTnn_QUH","outputId":"c965ffb0-cdef-4345-f17d-a634c19fe259","executionInfo":{"status":"error","timestamp":1716193244505,"user_tz":-540,"elapsed":121888,"user":{"displayName":"김민경","userId":"05552883468747004724"}}},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"mount failed","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-3bb97b2f59e2>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# mount Google drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# now you can see files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         )\n\u001b[0;32m--> 282\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: mount failed"]}],"source":["# mount Google drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# now you can see files\n","!echo -e \"\\nNumber of Google drive files in /content/drive/My Drive/:\"\n","!ls -l \"/content/drive/My Drive/\" | wc -l\n","# by the way, you can run any linux command by putting a ! at the start of the line\n","\n","# by default everything gets executed and saved in /content/\n","!echo -e \"\\nCurrent directory:\"\n","!pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"phWTu0ph_nhP","executionInfo":{"status":"aborted","timestamp":1716193244508,"user_tz":-540,"elapsed":67,"user":{"displayName":"김민경","userId":"05552883468747004724"}}},"outputs":[],"source":["workspace_path = '/content/drive/MyDrive/COSE471/HW3/'  # Change this path!\n","print(f'Current Workspace: {workspace_path}')"]},{"cell_type":"markdown","metadata":{"id":"7Y2hj5A8-c9u"},"source":["### Loading in the Data\n","\n","Our goal is to classify emails as spam or not spam (referred to as \"ham\") using features generated from the text in the email.\n","\n","The dataset consists of email messages and their labels (0 for ham, 1 for spam). Your labeled training dataset contains 8348 labeled examples, and the test set contains 1000 unlabeled examples.\n","\n","Run the following cells to load in the data into DataFrames.\n","\n","The `train` DataFrame contains labeled data that you will use to train your model. It contains four columns:\n","\n","1. `id`: An identifier for the training example\n","1. `subject`: The subject of the email\n","1. `email`: The text of the email\n","1. `spam`: 1 if the email is spam, 0 if the email is ham (not spam)\n","\n","The `test` DataFrame contains 1000 unlabeled emails. You will predict labels for these emails and submit your predictions to Kaggle for evaluation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ybZYxrch-c9u","executionInfo":{"status":"aborted","timestamp":1716193244509,"user_tz":-540,"elapsed":65,"user":{"displayName":"김민경","userId":"05552883468747004724"}}},"outputs":[],"source":["original_training_data = pd.read_csv(f'{workspace_path}/train.csv')\n","test = pd.read_csv(f'{workspace_path}/test.csv')\n","\n","# Convert the emails to lower case as a first step to processing the text\n","original_training_data['email'] = original_training_data['email'].str.lower()\n","test['email'] = test['email'].str.lower()\n","\n","original_training_data.head()"]},{"cell_type":"markdown","metadata":{"id":"LYeMW2mz-c9v"},"source":["### Question 1a\n","First, let's check if our data contains any missing values.\n","\n","- Step1: Fill in the cell below to print the number of NaN values in each column. **Hint**: [pandas.isnull](https://pandas.pydata.org/docs/reference/api/pandas.isnull.html)\n","- Step2: If there are NaN values, replace them with appropriate filler values (i.e., NaN values in the `subject` or `email` columns should be replaced with empty strings).\n","- Step3: Print the number of NaN values in each column after this modification to verify that there are no NaN values left.\n","\n","<!--\n","BEGIN QUESTION\n","name: q1a\n","points: 1\n","-->"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vREZl_jS-c9v","executionInfo":{"status":"aborted","timestamp":1716193244510,"user_tz":-540,"elapsed":63,"user":{"displayName":"김민경","userId":"05552883468747004724"}}},"outputs":[],"source":["# BEGIN YOUR CODE\n","# -----------------------\n","print('Before imputation:')\n","print(original_training_data.isnull().sum())\n","original_training_data.fillna(value='', inplace=True)\n","print('------------')\n","print('After imputation:')\n","print(original_training_data.isnull().sum())\n","# -----------------------\n","# END YOUR CODE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vghjI4WO-c9v","executionInfo":{"status":"aborted","timestamp":1716193244511,"user_tz":-540,"elapsed":63,"user":{"displayName":"김민경","userId":"05552883468747004724"}}},"outputs":[],"source":["assert original_training_data.isnull().sum().sum() == 0\n","print_passed('Q1a: Passed all unit tests!')"]},{"cell_type":"markdown","metadata":{"id":"hDyNrsW0-c9v"},"source":["### Question 1b\n","\n","In the cell below, print the text of the first ham (i.e. 1st row) and the first spam email in the original training set.\n","\n","<!--\n","BEGIN QUESTION\n","name: q1b\n","points: 1\n","-->"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gRB6X5hP-c9w","executionInfo":{"status":"aborted","timestamp":1716193244513,"user_tz":-540,"elapsed":62,"user":{"displayName":"김민경","userId":"05552883468747004724"}}},"outputs":[],"source":["# BEGIN YOUR CODE\n","# -----------------------\n","first_ham = original_training_data.loc[original_training_data['spam'] == 0, 'email'][0]\n","first_spam = original_training_data.loc[original_training_data['spam'] == 1, 'email'].iloc[0]\n","# -----------------------\n","# END YOUR CODE\n","\n","print('The text of the first Ham:')\n","print('------------')\n","print(first_ham)\n","\n","print('The text of the first Spam:')\n","print('------------')\n","print(first_spam)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AEbvv1L7-c9w","executionInfo":{"status":"aborted","timestamp":1716193244514,"user_tz":-540,"elapsed":60,"user":{"displayName":"김민경","userId":"05552883468747004724"}}},"outputs":[],"source":["assert len(first_ham) == 359 and len(first_spam) == 444\n","print_passed('Q1b: Passed all unit tests!')"]},{"cell_type":"markdown","metadata":{"id":"ouvBVCH8-c9w"},"source":["### Question 1c\n","\n","Discuss one thing you notice that is different between the two emails that might relate to the identification of spam.\n","\n","<!--\n","BEGIN QUESTION\n","name: q1c\n","manual: True\n","points: 2\n","-->\n","<!-- EXPORT TO PDF -->"]},{"cell_type":"markdown","metadata":{"id":"_PkkYtvH-c9w"},"source":["Answer: The spam email makes exaggerated claims and discusses suspicious content whereas the ham email is more informational. Additionally, the spam email is formatted like an html document with html tags! Scanning for certain words/phrases and the exisitence of html tags can help in the identification of spam."]},{"cell_type":"markdown","metadata":{"id":"EEJ511_8-c9w"},"source":["## Training Validation Split\n","The training data is all the data we have available for both training models and **validating** the models that we train. We therefore need to split the training data into separate training and validation datsets. You will need this **validation data** to assess the performance of your classifier once you are finished training.\n","\n","Note that we set the seed (random_state) to 42. This will produce a pseudo-random sequence of random numbers that is the same for every student. **Do not modify this in the following questions, as our tests depend on this random seed.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lh57_56V-c9w","executionInfo":{"status":"aborted","timestamp":1716193244516,"user_tz":-540,"elapsed":61,"user":{"displayName":"김민경","userId":"05552883468747004724"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","train, val = train_test_split(\n","    original_training_data, test_size=0.1, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kbFU8MUl-c9x","executionInfo":{"status":"aborted","timestamp":1716193244517,"user_tz":-540,"elapsed":60,"user":{"displayName":"김민경","userId":"05552883468747004724"}}},"outputs":[],"source":["print(train.shape, val.shape)   # 더해서 8342 맞음"]},{"cell_type":"markdown","metadata":{"id":"TMf51RV8-c9x"},"source":["# Basic Feature Engineering\n","\n","We would like to take the text of an email and predict whether the email is **ham** or **spam**. This is a *classification* problem, and here we use logistic regression to train a classifier.\n","\n","Recall that to train an logistic regression model we need:\n"," - a numeric feature matrix $X$\n"," - a vector of corresponding binary labels $y$.\n","\n","Unfortunately, our data are text, not numbers. To address this, we can create numeric features derived from the email text and use those features for logistic regression:\n"," - Each row of $X$ is an email.\n"," - Each column of $X$ contains one feature for all the emails.\n","\n","We'll guide you through creating a simple feature, and you'll create more interesting ones when you are trying to increase your accuracy."]},{"cell_type":"markdown","metadata":{"id":"a5kzAWDe-c9x"},"source":["### Question 2\n","\n","Create a function called `words_in_texts` that takes in a list of `words` and a pandas Series of email `texts`. It should output a 2-dimensional NumPy array containing one row for each email text. The row should contain either a 0 or a 1 for each word in the list: 0 if the word doesn't appear in the text and 1 if the word does. For example:\n","\n","```\n",">>> words_in_texts(['hello', 'bye', 'world'],\n","                   pd.Series(['hello', 'hello worldhello']))\n","\n","array([[1, 0, 0],\n","       [1, 0, 1]])\n","```\n","\n","**Hint**: [pandas.Series.str.contains](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.contains.html)\n","\n","*The provided tests make sure that your function works correctly, so that you can use it for future questions.*\n","\n","<!--\n","BEGIN QUESTION\n","name: q2\n","points: 3\n","-->"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9OANL6hA-c9x","executionInfo":{"status":"aborted","timestamp":1716193244519,"user_tz":-540,"elapsed":61,"user":{"displayName":"김민경","userId":"05552883468747004724"}}},"outputs":[],"source":["def words_in_texts(words, texts):\n","    '''\n","    Args:\n","        words (list-like): words to find\n","        texts (Series): strings to search in\n","\n","    Returns:\n","        NumPy array of 0s and 1s with shape (n, p) where n is the\n","        number of texts and p is the number of words.\n","    '''\n","    # BEGIN YOUR CODE\n","    # -----------------------\n","    result = []\n","    for email in texts:\n","      check = []\n","      for word in words:\n","        if word in email:\n","          check.append(1)\n","        else:\n","          check.append(0)\n","      result.append(check)\n","    indicator_array = np.array(result)\n","    # -----------------------\n","    # END YOUR CODE\n","    return indicator_array"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ghfT7JNi-c9x","executionInfo":{"status":"aborted","timestamp":1716193244520,"user_tz":-540,"elapsed":60,"user":{"displayName":"김민경","userId":"05552883468747004724"}}},"outputs":[],"source":["assert np.allclose(\n","    words_in_texts(\n","        ['hello', 'bye', 'world'],\n","        pd.Series(['hello', 'hello worldhello'])),\n","    np.array([[1, 0, 0], [1, 0, 1]]))\n","\n","assert np.allclose(\n","    words_in_texts(\n","        ['a', 'b', 'c', 'd', 'e', 'f', 'g'],\n","        pd.Series(['a b c d ef g', 'a', 'b', 'c', 'd e f g', 'h', 'a h'])),\n","    np.array(\n","        [[1,1,1,1,1,1,1],\n","         [1,0,0,0,0,0,0],\n","         [0,1,0,0,0,0,0],\n","         [0,0,1,0,0,0,0],\n","         [0,0,0,1,1,1,1],\n","         [0,0,0,0,0,0,0],\n","         [1,0,0,0,0,0,0]]))\n","\n","print_passed('Q2: Passed all unit tests!')"]},{"cell_type":"markdown","metadata":{"id":"rmMhnJmR-c9x"},"source":["# Basic EDA\n","\n","We need to identify some features that allow us to distinguish spam emails from ham emails. One idea is to compare the distribution of a single feature in spam emails to the distribution of the same feature in ham emails.\n","\n","If the feature is itself a binary indicator (such as whether a certain word occurs in the text), this amounts to comparing the proportion of spam emails with the word to the proportion of ham emails with the word."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lOxun1Re-c9x","executionInfo":{"status":"aborted","timestamp":1716193244521,"user_tz":-540,"elapsed":59,"user":{"displayName":"김민경","userId":"05552883468747004724"}}},"outputs":[],"source":["from IPython.display import display, Markdown\n","df = pd.DataFrame({\n","    'word_1': [1, 0, 1, 0],\n","    'word_2': [0, 1, 0, 1],\n","    'type': ['spam', 'ham', 'ham', 'ham']\n","})\n","display(Markdown(\"> Our Original DataFrame has some words column and a type column. You can think of each row is a sentence, and the value of 1 or 0 indicates the number of occurances of the word in this sentence.\"))\n","display(df);\n","display(Markdown(\"> `melt` will turn columns into variale, notice how `word_1` and `word_2` become `variable`, their values are stoed in the value column\"))\n","display(df.melt(\"type\"))"]},{"cell_type":"markdown","metadata":{"id":"u1ng79qh-c9y"},"source":["We can create a bar chart like the one above comparing the proportion of spam and ham emails containing certain words. Choose a set of words that are different from the ones above, but also have different proportions for the two classes. Make sure that we only consider emails from `train`.\n","\n","<!--\n","BEGIN QUESTION\n","name: q3a\n","manual: True\n","format: image\n","points: 2\n","-->\n","<!-- EXPORT TO PDF format:image -->"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kCRGFEby-c9y","executionInfo":{"status":"aborted","timestamp":1716193244522,"user_tz":-540,"elapsed":59,"user":{"displayName":"김민경","userId":"05552883468747004724"}}},"outputs":[],"source":["# We must do this in order to preserve the ordering of emails to labels for words_in_texts\n","train=train.reset_index(drop=True)\n","\n","some_words = ['body', 'html', 'please', 'money', 'business', 'offer']\n","Phi_train = words_in_texts(some_words, train['email'])\n","\n","df = pd.DataFrame(data = Phi_train, columns = some_words)\n","df['label'] = train['spam']\n","\n","plt.figure(figsize=(8,8))\n","sns.barplot(x = \"variable\",\n","            y = \"value\",\n","            hue = \"label\",\n","            data = (df\n","                    .replace({'label':\n","                                {0 : 'Ham',\n","                                 1 : 'Spam'}})\n","                    .melt('label')\n","                    .groupby(['label', 'variable'])\n","                    .mean()\n","                    .reset_index()))\n","\n","plt.ylim([0, 1])\n","plt.xlabel('Words')\n","plt.ylabel('Proportion of Emails')\n","plt.legend(title = \"\")\n","plt.title(\"Frequency of Words in Spam/Ham Emails\")\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"B6iIHbGL-c9y"},"source":["### Question 3\n","\n","When the feature is binary, it makes sense to compare its proportions across classes (as in the previous question). Otherwise, if the feature can take on numeric values, we can compare the distributions of these values for different classes.\n","\n","Create a *class conditional density plot* like the one above (using `sns.distplot`), comparing the distribution of the length of spam emails to the distribution of the length of ham emails in the training set. Set the x-axis limit from 0 to 50000.\n","\n","<!--\n","BEGIN QUESTION\n","name: q3b\n","manual: True\n","format: image\n","points: 2\n","-->\n","<!-- EXPORT TO PDF format:image -->"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WOhTQJkM-c9y","executionInfo":{"status":"aborted","timestamp":1716193244523,"user_tz":-540,"elapsed":58,"user":{"displayName":"김민경","userId":"05552883468747004724"}}},"outputs":[],"source":["# BEGIN SOLUTION\n","train['email_length'] = train['email'].apply(len)\n","ham = train[original_training_data['spam'] == 1]['email_length']\n","spam = train[original_training_data['spam'] == 0]['email_length']\n","\n","plt.figure(figsize=(6,4))\n","sns.distplot(spam, label='Spam', hist = False)\n","sns.distplot(ham, label='Ham', hist = False)\n","\n","plt.xlim([0, 50000])\n","plt.ylim([0, 0.00020])\n","plt.xlabel('Length of email body')\n","plt.ylabel('Distribuition')\n","plt.tight_layout()\n","plt.show()\n","# END SOLUTION"]},{"cell_type":"markdown","metadata":{"id":"kGxhfFNy-c9y"},"source":["## Basic Classification\n","\n","Notice that the output of `words_in_texts(words, train['email'])` is a numeric matrix containing features for each email. This means we can use it directly to train a classifier!"]},{"cell_type":"markdown","metadata":{"id":"AWxulxZ2-c9y"},"source":["### Question 4\n","\n","We've given you 5 words that might be useful as features to distinguish spam/ham emails. Use these words as well as the `train` DataFrame to create two NumPy arrays: `X_train` and `Y_train`.\n","\n","- `X_train` should be a matrix of 0s and 1s created by using your `words_in_texts` function on all the emails in the training set.\n","\n","- `Y_train` should be a vector of the correct labels for each email in the training set.\n","\n","*The provided tests check that the dimensions of your feature matrix (X) are correct, and that your features and labels are binary (i.e. consists of 0 and 1, no other values). It does not check that your function is correct; that was verified in a previous question.*\n","\n","<!--\n","BEGIN QUESTION\n","name: q4\n","points: 2\n","-->"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q2iQ0YrI-c9y","executionInfo":{"status":"aborted","timestamp":1716193244523,"user_tz":-540,"elapsed":57,"user":{"displayName":"김민경","userId":"05552883468747004724"}}},"outputs":[],"source":["some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n","\n","# BEGIN YOUR CODE\n","# -----------------------\n","X_train = words_in_texts(some_words, train['email']) # need to isolate text column in train\n","Y_train = train['spam'].values\n","# -----------------------\n","# END YOUR CODE\n","\n","X_train[:5], Y_train[:5]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A9sVGEvx-c9y","executionInfo":{"status":"aborted","timestamp":1716193244524,"user_tz":-540,"elapsed":56,"user":{"displayName":"김민경","userId":"05552883468747004724"}}},"outputs":[],"source":["assert X_train.shape == (7513, 5)\n","assert len(np.unique(X_train)) == 2\n","assert len(np.unique(Y_train)) == 2\n","\n","print_passed('Q4: Passed all unit tests!')"]},{"cell_type":"markdown","metadata":{"id":"s5zxFW5J-c9y"},"source":["### Question 5\n","\n","Now we have matrices we can give to scikit-learn!\n","\n","- Using the [`LogisticRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) classifier, train a logistic regression model using `X_train` and `Y_train`.\n","- Then, output the accuracy of the model (on the training data) in the cell below. You should get an accuracy around 75\\%.\n","\n","<!--\n","BEGIN QUESTION\n","name: q5\n","points: 2\n","-->"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VL7_VYxL-c9y","executionInfo":{"status":"aborted","timestamp":1716193244525,"user_tz":-540,"elapsed":56,"user":{"displayName":"김민경","userId":"05552883468747004724"}}},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","\n","# BEGIN YOUR CODE\n","# -----------------------\n","model = LogisticRegression()\n","model.fit(X_train, Y_train)\n","Y_train_prediction= model.predict(X_train)\n","\n","training_accuracy = accuracy_score(Y_train,Y_train_prediction)\n","# -----------------------\n","# END YOUR CODE\n","\n","print(\"Training Accuracy: \", training_accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T4LqNCSb-c9z","executionInfo":{"status":"aborted","timestamp":1716193244525,"user_tz":-540,"elapsed":55,"user":{"displayName":"김민경","userId":"05552883468747004724"}}},"outputs":[],"source":["assert training_accuracy > 0.72\n","print_passed('Q5: Passed all unit tests!')"]},{"cell_type":"markdown","metadata":{"id":"3jv3rfgv-c9z"},"source":["## Evaluating Classifiers"]},{"cell_type":"markdown","metadata":{"id":"mEVZsTjS-c9z"},"source":["That doesn't seem too shabby! But the classifier you made above isn't as good as this might lead us to believe. First, we are evaluating accuracy on the training set, which may lead to a misleading accuracy measure, especially if we used the training set to identify discriminative features. In future parts of this analysis, it will be safer to hold out some of our data for model validation and comparison.\n","\n","Presumably, our classifier will be used for **filtering**, i.e. preventing messages labeled `spam` from reaching someone's inbox. There are two kinds of errors we can make:\n","- False positive (FP): a ham email gets flagged as spam and filtered out of the inbox.\n","- False negative (FN): a spam email gets mislabeled as ham and ends up in the inbox.\n","\n","These definitions depend both on the true labels and the predicted labels. False positives and false negatives may be of differing importance, leading us to consider more ways of evaluating a classifier, in addition to overall accuracy:\n","\n","**Precision** measures the proportion $\\frac{\\text{TP}}{\\text{TP} + \\text{FP}}$ of emails flagged as spam that are actually spam.\n","\n","**Recall** measures the proportion $\\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$ of spam emails that were correctly flagged as spam.\n","\n","**False-alarm rate** measures the proportion $\\frac{\\text{FP}}{\\text{FP} + \\text{TN}}$ of ham emails that were incorrectly flagged as spam.\n","\n","The following image might help:\n","\n","<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/700px-Precisionrecall.svg.png\" width=\"500px\">\n","\n","Note that a true positive (TP) is a spam email that is classified as spam, and a true negative (TN) is a ham email that is classified as ham."]},{"cell_type":"markdown","metadata":{"id":"TikK5QTS-c9z"},"source":["### Question 6a\n","\n","Suppose we have a classifier `zero_predictor` that always predicts 0 (never predicts positive). How many false positives and false negatives would this classifier have if it were evaluated on the training set and its results were compared to `Y_train`? Fill in the variables below (answers can be hard-coded):\n","\n","<!--\n","BEGIN QUESTION\n","name: q6a\n","points: 1\n","-->"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UH8R7hKj-c9z","executionInfo":{"status":"aborted","timestamp":1716193244526,"user_tz":-540,"elapsed":55,"user":{"displayName":"김민경","userId":"05552883468747004724"}}},"outputs":[],"source":["# BEGIN YOUR CODE\n","# -----------------------\n","zero_predictor_fp = 0\n","zero_predictor_fn = 0\n","for correct_label in Y_train:\n","  if correct_label == 1:\n","    zero_predictor_fn += 1\n","# -----------------------\n","# END YOUR CODE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_n0eCG3p-c9z","executionInfo":{"status":"aborted","timestamp":1716193244526,"user_tz":-540,"elapsed":55,"user":{"displayName":"김민경","userId":"05552883468747004724"}}},"outputs":[],"source":["assert zero_predictor_fp + zero_predictor_fn == 1918\n","print_passed('Q6a: Passed all unit tests!')"]},{"cell_type":"markdown","metadata":{"id":"EwZ7pTRx-c9z"},"source":["### Question 6b\n","\n","What are the accuracy and recall of `zero_predictor` (classifies every email as ham) on the training set? Do NOT use any `sklearn` functions.\n","\n","<!--\n","BEGIN QUESTION\n","name: q6b\n","points: 1\n","-->"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8QNmzlhq-c9z","executionInfo":{"status":"aborted","timestamp":1716193244527,"user_tz":-540,"elapsed":55,"user":{"displayName":"김민경","userId":"05552883468747004724"}}},"outputs":[],"source":["# BEGIN YOUR CODE\n","# -----------------------\n","total = len(Y_train)\n","true_negative = 0\n","for correct_label in Y_train:\n","  if correct_label == 0:\n","    true_negative += 1\n","true_positive = 0 # 0 predictor will never predict 1\n","\n","zero_predictor_acc = (true_positive + true_negative)/total\n","\n","zero_predictor_recall = true_positive/(true_positive + zero_predictor_fn)\n","# -----------------------\n","# END YOUR CODE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ruHICzWJ-c9z","executionInfo":{"status":"aborted","timestamp":1716193244528,"user_tz":-540,"elapsed":55,"user":{"displayName":"김민경","userId":"05552883468747004724"}}},"outputs":[],"source":["assert np.isclose(zero_predictor_acc + zero_predictor_recall, 0.7447091707706642)\n","print_passed('Q6b: Passed all unit tests!')"]},{"cell_type":"markdown","metadata":{"id":"9iX-Z_qX-c9z"},"source":["### Question 6c\n","\n","Compute the precision, recall, and false-alarm rate of the `LogisticRegression` classifier created and trained in Question 5. **Note: Do NOT use any `sklearn` built-in functions.**\n","\n","<!--\n","BEGIN QUESTION\n","name: q6d\n","points: 2\n","-->"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WmM7bi3g-c9z","executionInfo":{"status":"aborted","timestamp":1716193244529,"user_tz":-540,"elapsed":56,"user":{"displayName":"김민경","userId":"05552883468747004724"}}},"outputs":[],"source":["# BEGIN YOUR CODE\n","# -----------------------\n","logistic_tp = ((Y_train == 1) & (Y_train_prediction == 1)).sum() #true_positive\n","logistic_fp = ((Y_train == 0) & (Y_train_prediction == 1)).sum() # false positive\n","\n","logistic_tn = ((Y_train == 0) & (Y_train_prediction == 0)).sum() # true negative\n","logistic_fn = ((Y_train == 1) & (Y_train_prediction == 0)).sum() # false negative\n","\n","logistic_predictor_precision = logistic_tp/(logistic_tp + logistic_fp)\n","logistic_predictor_recall = logistic_tp / (logistic_tp + logistic_fn)\n","logistic_predictor_far = logistic_fp / (logistic_fp + logistic_tn)\n","# -----------------------\n","# END YOUR CODE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l1ksLYsZ-c9z","executionInfo":{"status":"aborted","timestamp":1716193244529,"user_tz":-540,"elapsed":55,"user":{"displayName":"김민경","userId":"05552883468747004724"}}},"outputs":[],"source":["assert np.isclose(logistic_predictor_precision, 0.6422287390029325)\n","assert np.isclose(logistic_predictor_recall, 0.11418143899895725)\n","assert np.isclose(logistic_predictor_far, 0.021805183199285077)\n","print_passed('Q6c: Passed all unit tests!')"]},{"cell_type":"markdown","metadata":{"id":"SgF9D88T-c9z"},"source":["### Question 6d\n","\n","1. Our logistic regression classifier got 75.6% prediction accuracy (number of correct predictions / total). How does this compare with predicting 0 for every email?\n","1. Given the word features we gave you above, name one reason this classifier is performing poorly. Hint: Think about how prevalent these words are in the email set.\n","1. Which of these two classifiers would you prefer for a spam filter and why? Describe your reasoning and relate it to at least one of the evaluation metrics you have computed so far.\n","\n","<!--\n","BEGIN QUESTION\n","name: q6f\n","manual: True\n","points: 3\n","-->\n","<!-- EXPORT TO PDF -->"]},{"cell_type":"markdown","metadata":{"id":"xDhUZqqt-c9z"},"source":["Answer:\n","1. Comparing our logsitic regression classifier to our zero predictor shows that the logistic regression is only marginally better. THe zero predictor had an accuracy of 74.5% which is only 1.1% less the logsitic regression classifier. Hence, our logsitic regression is not a very good model.\n","\n","2. The reason our classifier is performing poorly is that the given word list includes words that show up in many ham emails. We should analyze our data to find words that are more common in spam emails.\n","\n","3. I would prefer the logistic regression as a spam filter because it actually flags some emails as spam since it's recall rate is 11.4%. On the other hand, the zero predictor never flags any emails as spam so all emails would pass through into our inbox (the recall rate is 0%). The zero_predictor basically has no effect on our inbox. It is more efficient for the logistic regression to make some mistakes in incorrectly predicting ham emails as spam and then manually checking the spam inbox every once in a while."]},{"cell_type":"markdown","metadata":{"id":"HVm_NmgG-c9z"},"source":["# Part II - Moving Forward\n","\n","With this in mind, it is now your task to make the spam filter more accurate. In order to get full credit on the accuracy part of this assignment, you must get at least **88%** accuracy on the `validation` set.\n","\n","Here are some ideas for improving your model:\n","\n","1. Finding better features based on the email text. Some example features are:\n","    1. Number of characters in the subject / body\n","    1. Number of words in the subject / body\n","    1. Use of punctuation (e.g., how many '!' were there?)\n","    1. Number / percentage of capital letters\n","    1. Whether the email is a reply to an earlier email or a forwarded email\n","1. Finding better words to use as features. Which words are the best at distinguishing emails? This requires digging into the email text itself.\n","1. Better data processing. For example, many emails contain HTML as well as text. You can consider extracting out the text from the HTML to help you find better words. Or, you can match HTML tags themselves, or even some combination of the two.\n","1. Model selection. You can adjust parameters of your model (e.g. the regularization parameter) to achieve higher accuracy. Recall that you should use cross-validation to do feature and model selection properly! Otherwise, you will likely overfit to your training data.\n","\n","You may use whatever method you prefer in order to create features, but **you are not allowed to import any external feature extraction libraries**. In addition, **you are only allowed to train logistic regression models**. No random forests, k-nearest-neighbors, neural nets, etc."]},{"cell_type":"markdown","metadata":{"id":"6YXT9eVw-c90"},"source":["### Question 7: EDA\n","\n","In the cell below, show a visualization that you used to select features for your model. Include both\n","\n","1. A plot showing something meaningful about the data that helped you during feature / model selection.\n","2. 2-3 sentences describing what you plotted and what its implications are for your features.\n","\n","Feel free to create as many plots as you want in your process of feature selection, but select one for the response cell below.\n","\n","**You should not just produce an identical visualization to question 3.** Specifically, don't show us a bar chart of proportions, or a one-dimensional class-conditional density plot. Any other plot is acceptable, as long as it comes with thoughtful commentary. Here are some ideas:\n","\n","1. Consider the correlation between multiple features (look up correlation plots and `sns.heatmap`).\n","1. Try to show redundancy in a group of features (e.g. `body` and `html` might co-occur relatively frequently, or you might be able to design a feature that captures all html tags and compare it to these).\n","1. Visualize which words have high or low values for some useful statistic.\n","1. Visually depict whether spam emails tend to be wordier (in some sense) than ham emails."]},{"cell_type":"markdown","metadata":{"id":"w4dBsZ3L-c90"},"source":["Generate your visualization in the cell below and provide your description in a comment.\n","\n","<!--\n","BEGIN QUESTION\n","name: q8\n","manual: True\n","format: image\n","points: 6\n","-->\n","<!-- EXPORT TO PDF format:image -->"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fFwkgESs-c90","executionInfo":{"status":"aborted","timestamp":1716193244530,"user_tz":-540,"elapsed":56,"user":{"displayName":"김민경","userId":"05552883468747004724"}}},"outputs":[],"source":["# Write your description (2-3 sentences) as a comment here:\n","#\n","#\n","#\n","\n","# Write the code to generate your visualization here:\n","..."]},{"cell_type":"markdown","metadata":{"id":"ltSWEnms-c90"},"source":["### Question 8: Precision-Recall Curve\n","\n","We can trade off between precision and recall. In most cases we won't be able to get both perfect precision (i.e. no false positives) and recall (i.e. no false negatives), so we have to compromise.\n","\n","Recall that logistic regression calculates the probability that an example belongs to a certain class.\n","* Then, to classify an example we say that an email is spam if our classifier gives it $\\ge 0.5$ probability of being spam.\n","* However, *we can adjust that cutoff*: we can say that an email is spam only if our classifier gives it $\\ge 0.7$ probability of being spam.\n","\n","This is how we can trade off false positives and false negatives. The precision-recall curve shows this trade off for each possible cutoff probability. In the cell below, [plot a precision-recall curve](http://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html#plot-the-precision-recall-curve) for your final classifier.\n","\n","<!--\n","BEGIN QUESTION\n","name: q9\n","manual: True\n","points: 3\n","-->\n","<!-- EXPORT TO PDF -->"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nvi9Qw-U-c90","executionInfo":{"status":"aborted","timestamp":1716193244531,"user_tz":-540,"elapsed":56,"user":{"displayName":"김민경","userId":"05552883468747004724"}}},"outputs":[],"source":["from sklearn.metrics import precision_recall_curve\n","\n","# Note that you'll want to use the .predict_proba(...) method for your classifier\n","# instead of .predict(...) so you get probabilities, not classes\n","\n","# BEGIN YOUR CODE\n","# -----------------------\n","...\n","# -----------------------\n","# END YOUR CODE"]},{"cell_type":"markdown","metadata":{"id":"DACE1sh--c90"},"source":["### Congratulations! You have completed HW 3.\n","\n","Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output.,\n","\n","**Please save before submitting!**\n","\n","Please generate pdf as follows and submit it to Gradescope.\n","\n","**File > Print Preview > Print > Save as pdf**\n","\n","<!-- EXPECT 9 EXPORTED QUESTIONS -->"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GYp-nNVhYkF2","executionInfo":{"status":"aborted","timestamp":1716193244531,"user_tz":-540,"elapsed":55,"user":{"displayName":"김민경","userId":"05552883468747004724"}}},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1nJpJeXwOSMXMFrGg8xqHVo3e0bGgu61q","timestamp":1716193082446}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":0}